{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "duplicateremove.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ViZTAOmcx14X",
        "outputId": "98cb0cd3-6a37-4378-b012-0ac35ada9e48"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /content/drive\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Vz1p24ezyWAT",
        "outputId": "e34294e3-7939-4931-e785-27664fee4bcc"
      },
      "source": [
        "import re\n",
        "import tweepy\n",
        "from tweepy import OAuthHandler\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "import sys\n",
        "import datetime\n",
        "import pandas as pd\n",
        "\n",
        "from textblob.classifiers import NaiveBayesClassifier as NBC\n",
        "from sklearn import model_selection, naive_bayes, svm\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "class TwitterClient(object):\n",
        "\t'''\n",
        "\tGeneric Twitter Class for sentiment analysis.\n",
        "\t'''\n",
        "\tdef __init__(self):\n",
        "\t\t'''\n",
        "\t\tClass constructor or initialization method.\n",
        "\t\t'''\n",
        "\t\t# keys and tokens from the Twitter Dev Console\n",
        "\t\tconsumer_key = 'Input key'\n",
        "\t\tconsumer_secret = 'Input key'\n",
        "\t\taccess_token = 'Input key'\n",
        "\t\taccess_token_secret = 'Input key'\n",
        "\n",
        "\t\t# attempt authentication\n",
        "\t\ttry:\n",
        "\t\t\t# create OAuthHandler object\n",
        "\t\t\tself.auth = OAuthHandler(consumer_key, consumer_secret)\n",
        "\t\t\t# set access token and secret\n",
        "\t\t\tself.auth.set_access_token(access_token, access_token_secret)\n",
        "\t\t\t# create tweepy API object to fetch tweets\n",
        "\t\t\tself.api = tweepy.API(self.auth)\n",
        "\t\texcept:\n",
        "\t\t\tprint(\"Error: Authentication Failed\")\n",
        "\n",
        "\tdef clean_tweet(self, tweet):\n",
        "\t\t'''\n",
        "\t\tUtility function to clean tweet text by removing links, special characters\n",
        "\t\tusing simple regex statements.\n",
        "\t\t'''\n",
        "\t\treturn ' '.join(re.sub(\"(@[A-Za-z0-9]+)|([^0-9A-Za-z \\t])|(\\w+:\\/\\/\\S+)\", \" \", tweet).split())\n",
        "\n",
        "\tdef get_tweet_sentiment(self, tweet):\n",
        "\t\t'''\n",
        "\t\tUtility function to classify sentiment of passed tweet\n",
        "\t\tusing textblob's sentiment method\n",
        "\t\t'''\n",
        "\t\t# create TextBlob object of passed tweet text\n",
        "\t\tanalysis = TextBlob(self.clean_tweet(tweet))\n",
        "\t\t# set sentiment\n",
        "\t\tif analysis.sentiment.polarity > 0:\n",
        "\t\t\treturn 'positive'\n",
        "\t\telif analysis.sentiment.polarity == 0:\n",
        "\t\t\treturn 'neutral'\n",
        "\t\telse:\n",
        "\t\t\treturn 'negative'\n",
        "\n",
        "\tdef get_tweets(self, query,lang,count):\n",
        "\t\t'''\n",
        "\t\tMain function to fetch tweets and parse them.\n",
        "\t\t'''\n",
        "\t\t# empty list to store parsed tweets\n",
        "\t\ttweets = []\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\t# call twitter api to fetch tweets\n",
        "\t\t\tfetched_tweets = self.api.search(q= query, lang = lang, count=count)\n",
        "\n",
        "\t\t\t# parsing tweets one by one\n",
        "\t\t\tfor tweet in fetched_tweets:\n",
        "\t\t\t\t# empty dictionary to store required params of a tweet\n",
        "\t\t\t\tparsed_tweet = {}\n",
        "\n",
        "\t\t\t\tparsed_tweet['created_at'] = tweet.created_at\n",
        "\t\t\t\t# saving text of tweet\n",
        "\t\t\t\tparsed_tweet['text'] = tweet.text\n",
        "\t\t\t\t# saving sentiment of tweet\n",
        "\t\t\t\tparsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n",
        "\n",
        "\t\t\t\t# appending parsed tweet to tweets list\n",
        "\t\t\t\tif tweet.retweet_count > 0:\n",
        "\t\t\t\t\t# if tweet has retweets, ensure that it is appended only once\n",
        "\t\t\t\t\tif parsed_tweet not in tweets:\n",
        "\t\t\t\t\t\ttweets.append(parsed_tweet)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\ttweets.append(parsed_tweet)\n",
        "\n",
        "\t\t\t# return parsed tweets\n",
        "\t\t\treturn tweets\n",
        "\n",
        "\t\texcept tweepy.TweepError as e:\n",
        "\t\t\t# print error (if any)\n",
        "\t\t\tprint(\"Error : \" + str(e))\n",
        "\n",
        "\tdef get_tweets_time(self, env, query, since, until):\n",
        "\t\t'''\n",
        "\t\tMain function to fetch tweets and parse them.\n",
        "\t\t'''\n",
        "\t\t# empty list to store parsed tweets\n",
        "\t\ttweets = []\n",
        "\n",
        "\t\ttry:\n",
        "\t\t\t# call twitter api to fetch tweets\n",
        "\t\t\tfetched_tweets = self.api.search_full_archive(environment_name = env, query = query,fromDate= since, toDate= until)\n",
        "\n",
        "\t\t\t# parsing tweets one by one\n",
        "\t\t\tfor tweet in fetched_tweets:\n",
        "\t\t\t\t# empty dictionary to store required params of a tweet\n",
        "\t\t\t\tparsed_tweet = {}\n",
        "\n",
        "\t\t\t\tparsed_tweet['created_at'] = tweet.created_at\n",
        "\t\t\t\t# saving text of tweet\n",
        "\t\t\t\tparsed_tweet['text'] = tweet.text\n",
        "\t\t\t\t# saving sentiment of tweet\n",
        "\t\t\t\tparsed_tweet['sentiment'] = self.get_tweet_sentiment(tweet.text)\n",
        "\n",
        "\t\t\t\t# appending parsed tweet to tweets list\n",
        "\t\t\t\tif tweet.retweet_count > 0:\n",
        "\t\t\t\t\t# if tweet has retweets, ensure that it is appended only once\n",
        "\t\t\t\t\tif parsed_tweet not in tweets:\n",
        "\t\t\t\t\t\ttweets.append(parsed_tweet)\n",
        "\t\t\t\telse:\n",
        "\t\t\t\t\ttweets.append(parsed_tweet)\n",
        "\n",
        "\t\t\t# return parsed tweets\n",
        "\t\t\treturn tweets\n",
        "\n",
        "\t\texcept tweepy.TweepError as e:\n",
        "\t\t\t# print error (if any)\n",
        "\t\t\tprint(\"Error : \" + str(e))\n",
        "\n",
        "def main():\n",
        "\t# creating object of TwitterClient Class\n",
        "\tapi = TwitterClient()\n",
        "\tkeyword = 'GE14' #'malaysiamemilih' and 'GE14' and 'pru14' and 'battle4my' and 'myundi'#input(\"Please enter keyword or hashtag to search: \")\n",
        "\tdate_since='201703102359' #kalau nak guna fix time tukar dr sini ja. kalau mau input guna input function copy jak dr comment\n",
        "\tdate_until='201705080000' #input(\"Please enter end time: \")\n",
        "\tlanguage = 'en' #input(\"Please enter language prefer: \") en = english my/msa = malay\n",
        "\t# calling function to get tweets latest 1 week \n",
        "\ttweets = api.get_tweets(query = keyword, lang=language,count=100) #normal\n",
        "\t#calling with full archive \n",
        "\ttweets = api.get_tweets_time(env= 'Hello', query = (keyword),since = date_since,until = date_until) #set the time \n",
        "\n",
        "\t#print(tweets)\n",
        "\tcreat = []\n",
        "\ttexts = []\n",
        "\tsen = []\n",
        "\tfor tweet in tweets:\n",
        "\t\t#print(tweet['created_at'],tweet['text'],tweet['sentiment']) \n",
        "\t\tcreat.append(tweet['created_at'])\n",
        "\t\ttexts.append(tweet['text'])\n",
        "\t\tsen.append(tweet['sentiment'])\n",
        "\tdata={'Create_at': creat, 'Text':texts,'Sentiment':sen}\n",
        "\tresult = pd.DataFrame(data, columns= ['Create_at','Text','Sentiment'])\n",
        "\t#print(result)\n",
        "\twriter = pd.ExcelWriter('./original.xlsx')\n",
        "\tresult.to_excel(writer)\n",
        "\twriter.save()\n",
        "\t#print(\"success save data in excel\")\n",
        "  \n",
        "  #call the excel\n",
        "\tdf = pd.read_excel('original.xlsx')\n",
        "\tprint(len(df)) \n",
        "\timport re\n",
        "  \n",
        "\tdef deEmojify(text):\n",
        "\t\tregrex_pattern = re.compile(pattern = \"[\"\n",
        "\t\t\t\tu\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
        "\t\t\t\tu\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
        "\t\t\t\tu\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
        "\t\t\t\tu\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
        "\t\t\t\t\t\t\t\t\t\t\t\t\t\t\"]+\", flags = re.UNICODE)\n",
        "\t\treturn regrex_pattern.sub(r'',text)\n",
        "\n",
        "\tfor i in range(len(df)):\n",
        "\t\ttxt = df.loc[i][\"Text\"]\n",
        "\t\ttxt = deEmojify(txt)\n",
        "\t\ttxt=re.sub(r'@[A-Z0-9a-z_:]+','',txt)#replace username-tags\n",
        "\t\ttxt=re.sub(r'^[RT ]+','',txt)#replace RT-tags\n",
        "\t\ttxt = re.sub('https?://[A-Za-z0-9./]+','',txt)#replace URLs\n",
        "\t\ttxt = re.sub('\\'','',txt) #remove symbol\n",
        "\t\ttxt = re.sub('\\â€™','',txt) #remove symbol\n",
        "\t\ttxt = re.sub('\\â€˜',' ',txt) #remove symbol\n",
        "\t\ttxt = re.sub('\\â€¦','',txt) #remove symbol\n",
        "\t\ttxt = re.sub('\\ðŸ¤£','',txt) #remove symbol\n",
        "\t\ttxt = re.sub('\\n','',txt) #remove enter\n",
        "\t\ttxt = txt.rstrip() #remove space behind sentences\n",
        "\t\t#txt = re.sub(\"^\\d+\\s|\\s\\d+\\s|\\s\\d+$\", \" \", txt) #remove number\n",
        "\t\t#txt=re.sub(\"#\", \"\",txt)#replace hashtags\n",
        "\t\tdf.at[i,\"Text\"]=txt\n",
        "\n",
        "\tnan_value = float('NaN')\n",
        "\tdf.replace('', nan_value, inplace=True)\n",
        "\tdf.dropna(subset = ['Text'], inplace=True)\n",
        "\tdf = df.drop_duplicates(subset=['Text'])\n",
        "\n",
        "\t#save remove duplicate and retweet\n",
        "\tresult2 = pd.DataFrame(df, columns= ['Create_at','Text','Sentiment'])\n",
        "\twriter2 = pd.ExcelWriter('./pre-processing.xlsx') #after preprocessing\n",
        "\tresult2.to_excel(writer2)\n",
        "\twriter2.save()  \n",
        "\tprint(\"success save data in excel\") \n",
        "\t#call the excel\n",
        "\tdf2 = pd.read_excel('./pre-processing.xlsx')\n",
        "\tresult2 = pd.DataFrame(df2, columns= ['Create_at','Text','Sentiment'])\n",
        "\twriter2 = pd.ExcelWriter('./removeduplicate.xlsx')\n",
        "\tresult2.to_excel(writer2)\n",
        "\twriter2.save()\n",
        "\tprint(len(df2))\n",
        " \n",
        "\tprint(\"\\n \")\n",
        "\tprint(\"THE NUMBER OF TWEET EXTRACT FROM HASHTAG = \" + str(len(df2))) #how many number can extract based on the tweeter package u used sandbox only 100 , search only 1 week latest data\n",
        "\tif len(df2)==0:\n",
        "\t\tprint('There is no data for this language')\n",
        "\telse:\n",
        "\t\tTotal = len(df2.Sentiment)\n",
        "\t\tptweet = 0\n",
        "\t\tntweet = 0\n",
        "\t\tneutral = 0\n",
        "\t\tfor i in range(len(df2)):\n",
        "\t\t\ttxt = df2.loc[i][\"Sentiment\"]\n",
        "\t\t\tif txt == 'positive':\n",
        "\t\t\t\tptweet += 1\n",
        "\t\t\telif txt == 'negative':\n",
        "\t\t\t\tntweet += 1\n",
        "\t\t\telse: \n",
        "\t\t\t\tneutral +=1\n",
        "\n",
        "\t\tprint(\"Positive tweets percentage: \" + str(100*(ptweet/Total)) + '%')\n",
        "\t\tprint(\"Negative tweets percentage: \" + str(100*(ntweet/Total)) + '%')\n",
        "\t\tprint(\"Neutral tweets percentage: \" + str(100*(neutral/Total)) + '%')\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "\t# calling main function\n",
        "\tmain()\n"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "100\n",
            "success save data in excel\n",
            "60\n",
            "\n",
            " \n",
            "THE NUMBER OF TWEET EXTRACT FROM HASHTAG = 60\n",
            "Positive tweets percentage: 35.0%\n",
            "Negative tweets percentage: 11.666666666666666%\n",
            "Neutral tweets percentage: 53.333333333333336%\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}